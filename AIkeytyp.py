import sys
import cv2
import mediapipe as mp
import numpy as np
import torch
import torch.nn as nn
import pyautogui
import time
from collections import deque
from ultralytics import YOLO
import threading
import cpuinfo

from PySide6.QtWidgets import QApplication, QMainWindow, QWidget, QLabel, QVBoxLayout, QHBoxLayout, QPushButton, QSplashScreen, QMessageBox
from PySide6.QtGui import QImage, QPixmap
from PySide6.QtCore import Qt, QObject, Signal, QThread

# ===== ì„¤ì • =====
SEQUENCE_LENGTH       = 20
TCN_PATH              = 'ai_motion_keyboard_GPU/assets/models/final_model_unified_v3.pt'
YOLO_PATH             = 'ai_motion_keyboard_GPU/assets/models/poker_tenkey(heavy).pt'
DEBOUNCE_MS           = 200   # ê°™ì€ ì†ì—ì„œ ì—°ì† ì…ë ¥ ë°©ì§€ (ë°€ë¦¬ì´ˆ)

# â–¼â–¼â–¼ [ì¶”ê°€] ì¹´ë©”ë¼ ì„ íƒ ìŠ¤ìœ„ì¹˜ â–¼â–¼â–¼
USE_NETWORK_CAM = False  # True: ë„¤íŠ¸ì›Œí¬ ì¹´ë©”ë¼, False: ë¡œì»¬ ì›¹ìº (0ë²ˆ)
NETWORK_CAM_URL = "http://192.168.219.100:4747/video?1280x720"

# ---- ì•ˆì •í™” íŒŒë¼ë¯¸í„° (ë¯¼ê°ë„ ì¡°ì ˆìš©) ----
PRED_ON_THRESH   = 0.75  # ì¼œì§ˆ ë•Œ ì„ê³„(ë†’ì¼ìˆ˜ë¡ ëœ ë¯¼ê°)
PRED_OFF_THRESH  = 0.70  # êº¼ì§ˆ ë•Œ ì„ê³„(ë‚®ì¶œìˆ˜ë¡ ë¹¨ë¦¬ êº¼ì§)
EMA_ALPHA        = 0.60  # í™•ë¥  EMA ê³„ìˆ˜(0~1). ë‚®ì¶”ë©´ ë” ë§¤ëˆ, ë°˜ì‘ì„±â†“
MIN_ON_FRAMES    = 2     # ON íŒì •ì— í•„ìš”í•œ ì—°ì† í”„ë ˆì„ ìˆ˜
MIN_OFF_FRAMES   = 2     # OFF íŒì •ì— í•„ìš”í•œ ì—°ì† í”„ë ˆì„ ìˆ˜
REFRACTORY_MS    = 180   # í‚¤ ì…ë ¥ í›„ ë¶ˆì‘ê¸° (ì—°íƒ€ ë°©ì§€)

# ---- [NEW] í‚¤ë³´ë“œ ìë™ ì¸ì‹ ì„¤ì • ----
VALID_KEY_COUNTS      = [87, 61] # ìœ íš¨ í‚¤ë³´ë“œ í‚¤ ê°œìˆ˜ ëª©ë¡
MOVEMENT_THRESHOLD    = 4.5  # í‰ê·  í”½ì…€ ë³€í™”ëŸ‰ (ë‚®ì„ìˆ˜ë¡ ë¯¼ê°)
STABLE_TIME_REQUIRED  = 1.0  # ì•ˆì • ìƒíƒœ ìœ ì§€ í•„ìš” ì‹œê°„ (ì´ˆ)
CORRECTION_INTERVAL_S = 5.0  # ì£¼ê¸°ì  ìœ„ì¹˜ ë³´ì • ê°„ê²© (ì´ˆ)
RESET_KEY_COUNT_THRESHOLD = 1 # ì´ ê°œìˆ˜ ë¯¸ë§Œìœ¼ë¡œ ê°ì§€ë˜ë©´ ì¦‰ì‹œ ì¬ì¸ì‹
# =================


# ===== ê¸°ëŠ¥í‚¤ ë§¤í•‘ =====
key_name_map = {
    "Tlide": "`", "1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "7": "7", "8": "8", "9": "9", "0": "0", "Subtract": "subtract", "Add": "add",
    "Backspace": "backspace", "Tab": "tab", "Q": "q", "W": "w", "E": "e", "R": "r", "T": "t", "Y": "y", "U": "u", "I": "i", "O": "o", "P": "p",
    "Bracket1": "[", "Bracket2": "]", "Backslash": "\\", "Caps Lock": "capslock", "A": "a", "S": "s", "D": "d", "F": "f", "G": "g", "H": "h", "J": "j", "K": "k", "L": "l",
    "Semi_colon": ";", "Apostrophe": "'", "Enter": "enter", "left_Shift": "shift", "right_Shift": "shift", "Z": "z", "X": "x", "C": "c", "V": "v", "B": "b", "N": "n", "M": "m",
    "Comma": ",", "Period": ".", "Slash": "/", "left_Ctrl": "ctrl", "right_Ctrl": "ctrl", "left_Win": "winleft", "right_Win": "winright", "left_Alt": "alt",
    "Space": "space", "right_Alt": "hangul", "Menu": "menu", "Esc": "esc", "F1": "f1", "F2": "f2", "F3": "f3", "F4": "f4", "F5": "f5", "F6": "f6", "F7": "f7", "F8": "f8",
    "F9": "f9", "F10": "f10", "F11": "f11", "F12": "f12", "PrtSc": "printscreen", "Scroll": "scrolllock", "Pause": "pause", "Insert": "insert", "Home": "home", "PgUp": "pageup",
    "Delete": "delete", "End": "end", "PgDn": "pagedown", "up": "up", "left": "left", "down": "down", "right": "right"
}

# ===== [NEW] í™”ë©´ í‘œì‹œìš© ì´ë¦„ ë§µ =====
display_name_map = {
    "left_Shift": "LSH", "right_Shift": "RSH",
    "left_Ctrl": "LC", "right_Ctrl": "RC",
    "left_Win": "LW", "right_Win": "RW",
    "left_Alt": "LA", "right_Alt": "RA",
    "Caps Lock": "CAPS",
    "Enter": "ENT",
    "Tab": "TAB",
    "Backspace": "BSPC",

    # â–¼â–¼â–¼ ê¸°í˜¸/íŠ¹ìˆ˜í‚¤ ë§¤í•‘ ì¶”ê°€ â–¼â–¼â–¼
    "Tlide": "`",
    "Subtract": "-",
    "Add": "+",
    "Bracket1": "[",
    "Bracket2": "]",
    "Backslash": "\\",
    "Semi_colon": ";",
    "Apostrophe": "'",
    "Comma": ",",
    "Period": ".",
    "Slash": "/",
    # ... (ì›í•˜ëŠ” ë‹¤ë¥¸ í‚¤ë“¤ë„ ì¶”ê°€ ê°€ëŠ¥) ...
}

# ===== TCN ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ =====
class Chomp1d(nn.Module):
    def __init__(self, chomp): super().__init__(); self.chomp = chomp
    def forward(self, x): return x[:, :, :-self.chomp].contiguous()
class TemporalBlock(nn.Module):
    def __init__(self, in_ch, out_ch, kernel, dilation, padding, dropout):
        super().__init__();self.conv1=nn.utils.weight_norm(nn.Conv1d(in_ch,out_ch,kernel,padding=padding,dilation=dilation));self.chomp1=Chomp1d(padding);self.relu1=nn.ReLU();self.drop1=nn.Dropout(dropout);self.conv2=nn.utils.weight_norm(nn.Conv1d(out_ch,out_ch,kernel,padding=padding,dilation=dilation));self.chomp2=Chomp1d(padding);self.relu2=nn.ReLU();self.drop2=nn.Dropout(dropout);self.downsample=nn.Conv1d(in_ch,out_ch,1) if in_ch!=out_ch else None;self.relu=nn.ReLU()
    def forward(self,x):
        out=self.chomp1(self.conv1(x));out=self.drop1(self.relu1(out));out=self.chomp2(self.conv2(out));out=self.drop2(self.relu2(out));residual=x if self.downsample is None else self.downsample(x);return self.relu(out+residual)
class TCNModel(nn.Module):
    def __init__(self, num_inputs, num_channels, kernel_size, dropout, out_features):
        super().__init__();layers=[];
        for i,out_ch in enumerate(num_channels):
            in_ch=num_inputs if i==0 else num_channels[i-1];dilation=2**i;padding=(kernel_size-1)*dilation;layers.append(TemporalBlock(in_ch,out_ch,kernel_size,dilation,padding,dropout))
        self.tcn=nn.Sequential(*layers);self.linear=nn.Linear(num_channels[-1],out_features)
    def forward(self,x): y=self.tcn(x);y_last=y[:,:,-1];return self.linear(y_last)

# ===== í•˜ë“œì›¨ì–´ ìƒíƒœ í™•ì¸ =====
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
cpu_name, gpu_name = "", ""
print("\n" + "="*30); print("   HARDWARE STATUS CHECK"); print("="*30)
try:
    cpu_name = cpuinfo.get_cpu_info()['brand_raw']
    print(f"âœ… CPU Detected: {cpu_name}")
except Exception:
    cpu_name = "CPU (Unknown)"
if device.type == 'cuda':
    gpu_name = torch.cuda.get_device_name(0)
    print(f"âœ… GPU (CUDA) is available!: {gpu_name}")
else:
    gpu_name = "N/A (CPU Mode)"
print("="*30 + "\n")

# ===== VideoStream í´ë˜ìŠ¤ (ë“¤ì—¬ì“°ê¸° ìˆ˜ì •) =====
class VideoStream:
    def __init__(self, src=0):
        # src íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì¹´ë©”ë¼ë¥¼ ì—½ë‹ˆë‹¤
        if isinstance(src, int):
            # srcê°€ ìˆ«ì(0, 1 ë“±)ì´ë©´ ë¡œì»¬ ì›¹ìº ìœ¼ë¡œ ê°„ì£¼í•˜ê³  CAP_DSHOWë¥¼ ì‚¬ìš©
            self.stream = cv2.VideoCapture(src, cv2.CAP_DSHOW)
            print(f"[INFO] Local webcam ({src}) starting with DSHOW backend.")
        else:
            # srcê°€ ë¬¸ìì—´ì´ë©´ ë„¤íŠ¸ì›Œí¬ ì¹´ë©”ë¼ë¡œ ê°„ì£¼
            self.stream = cv2.VideoCapture(src)
            print(f"[INFO] Network camera starting: {src}")

        if not self.stream.isOpened(): raise IOError(f"Cannot open video stream: {src}")
        (self.ret, self.frame) = self.stream.read()
        self.stopped = False
        self.thread = threading.Thread(target=self.update, args=())
        self.thread.daemon = True
        self.thread.start()

    def update(self):
        # ì´ ë©”ì„œë“œëŠ” __init__ê³¼ ë™ì¼í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë“¤ì—¬ì“°ê¸° ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
        while not self.stopped:
            (self.ret, self.frame) = self.stream.read()

    def read(self):
        # ì´ ë©”ì„œë“œëŠ” __init__ê³¼ ë™ì¼í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë“¤ì—¬ì“°ê¸° ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
        return self.frame

    def stop(self):
        # ì´ ë©”ì„œë“œëŠ” __init__ê³¼ ë™ì¼í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë“¤ì—¬ì“°ê¸° ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
        self.stopped = True
        self.thread.join()
        self.stream.release()

# ===== Worker í´ë˜ìŠ¤ =====
class Worker(QObject):
    finished = Signal()
    new_frame = Signal(np.ndarray)
    update_status = Signal(str)
    reference_keys_updated = Signal(str)
    preset_updated_signal = Signal(str) # í¬ë§·ëœ ì „ì²´ ë¬¸ìì—´ì„ ì „ë‹¬

    def __init__(self, vs):
        super().__init__()
        self.vs = vs
        self.running = True
        # --- ëª¨ë“  AI ëª¨ë¸ê³¼ ë³€ìˆ˜ë“¤ì„ í´ë˜ìŠ¤ ë©¤ë²„ë¡œ ì´ˆê¸°í™” ---
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = self.load_tcn_model_from_pt(TCN_PATH, self.device)
        self.keyboard_detector = YOLO(YOLO_PATH)
        self.mp_hands = mp.solutions.hands
        self.mp_drawing = mp.solutions.drawing_utils
        self.last_pressed_info = {'key_label': None, 'time': 0}

        # â–¼â–¼â–¼ í”„ë¦¬ì…‹ íŒŒë¼ë¯¸í„°ë¥¼ self ë³€ìˆ˜ë¡œ ì´ˆê¸°í™” â–¼â–¼â–¼
        self.PRED_ON_THRESH = 0
        self.PRED_OFF_THRESH = 0
        self.EMA_ALPHA = 0
        self.REFRACTORY_MS = 0

        self.corrected_boxes = []; self.initial_key_positions = []; self.reference_keys = []; self.reference_initial = {}; self.reference_current = {}
        self.captured_initial = False; self.last_correction_time = 0; self.lock = threading.Lock()
        self.prev_gray = None; self.stable_start_time = None
        self.seq_data = {'Right': deque(maxlen=SEQUENCE_LENGTH), 'Left': deque(maxlen=SEQUENCE_LENGTH)}
        self.effect_xy = {'Right': None, 'Left': None}; self.sm_prob = {'Right': 0.0, 'Left': 0.0}
        self.is_active = {'Right': False, 'Left': False}; self.prev_active = {'Right': False, 'Left': False}
        self.on_cnt = {'Right': 0, 'Left': 0}; self.off_cnt = {'Right': 0, 'Left': 0}; self.last_press_ms = {'Right': 0, 'Left': 0}

        # â–¼â–¼â–¼ ì…ë ¥ í™œì„±í™” ìƒíƒœ ë³€ìˆ˜ ì¶”ê°€ (ê¸°ë³¸ê°’: True) â–¼â–¼â–¼
        self.input_enabled = True

        # â–¼â–¼â–¼ í”„ë¦¬ì…‹ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ì¶”ê°€ â–¼â–¼â–¼
        self.presets = {
            "Sensitive": {"PRED_ON_THRESH": 0.65, "PRED_OFF_THRESH": 0.60, "EMA_ALPHA": 0.70, "REFRACTORY_MS": 180},
            "Balanced": {"PRED_ON_THRESH": 0.75, "PRED_OFF_THRESH": 0.70, "EMA_ALPHA": 0.60, "REFRACTORY_MS": 180},
            "Stable": {"PRED_ON_THRESH": 0.80, "PRED_OFF_THRESH": 0.70, "EMA_ALPHA": 0.60, "REFRACTORY_MS": 180},
            #"Very Stable": {"PRED_ON_THRESH": 0.90, "PRED_OFF_THRESH": 0.85,"EMA_ALPHA": 0.30, "REFRACTORY_MS": 300}
        }

    # Worker í´ë˜ìŠ¤ ë‚´ë¶€ (ì˜ˆ: __init__ ë©”ì„œë“œ ë‹¤ìŒ)
    def set_input_enabled(self, enabled):
        """UI ìŠ¤ë ˆë“œë¡œë¶€í„° ì‹ í˜¸ë¥¼ ë°›ì•„ ì…ë ¥ í™œì„±í™” ìƒíƒœë¥¼ ë³€ê²½í•˜ëŠ” ìŠ¬ë¡¯"""
        self.input_enabled = enabled
        print(f"[INFO] Keyboard input {'ENABLED' if enabled else 'DISABLED'}")

    def force_rerecognize(self):
        """UIë¡œë¶€í„° ì‹ í˜¸ë¥¼ ë°›ì•„ í‚¤ë³´ë“œ ì¬ì¸ì‹ì„ ê°•ì œí•˜ëŠ” ìŠ¬ë¡¯"""
        print("[INFO] Manual keyboard re-recognition triggered!")
        self.captured_initial = False
        self.stable_start_time = None
        self.reference_keys_updated.emit("Reference Keys: N/A")

    def apply_preset(self, preset_name):
        """UIë¡œë¶€í„° ì‹ í˜¸ë¥¼ ë°›ì•„ íƒ€ì´í•‘ ë¯¼ê°ë„ í”„ë¦¬ì…‹ì„ ì ìš©í•˜ëŠ” ìŠ¬ë¡¯"""
        if preset_name in self.presets:
            print(f"[INFO] Applying preset: {preset_name}")
            preset_values = self.presets[preset_name]

            # ì „ì—­ ë³€ìˆ˜ê°€ ì•„ë‹Œ í´ë˜ìŠ¤ ë©¤ë²„ ë³€ìˆ˜ë¥¼ ì§ì ‘ ìˆ˜ì •
            self.PRED_ON_THRESH = preset_values["PRED_ON_THRESH"]
            self.PRED_OFF_THRESH = preset_values["PRED_OFF_THRESH"]
            self.EMA_ALPHA = preset_values["EMA_ALPHA"]
            self.REFRACTORY_MS = preset_values["REFRACTORY_MS"]

            # â–¼â–¼â–¼ ë³€ê²½ëœ í”„ë¦¬ì…‹ ì •ë³´ë¥¼ UIë¡œ ë‹¤ì‹œ ë³´ë‚´ëŠ” ì‹ í˜¸ ë°œìƒ â–¼â–¼â–¼
            info_text = (f"Preset: {preset_name}\n"
                        f"ON:{self.PRED_ON_THRESH:.2f} OFF:{self.PRED_OFF_THRESH:.2f} "
                        f"EMA:{self.EMA_ALPHA:.2f}")
            self.preset_updated_signal.emit(info_text)

    # ... (ëª¨ë“  í—¬í¼ í•¨ìˆ˜ë“¤ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ì—¬ê¸°ì— ìœ„ì¹˜) ...
    def _first_block_conv1_weight(self, sd):
        cands=[];
        for k,v in sd.items():
            if k.startswith('tcn.') and (k.endswith('conv1.weight_v') or k.endswith('conv1.weight')):
                try:idx=int(k.split('.')[1])
                except:idx=9999
                cands.append((idx,k,v))
        if not cands:return None,None
        cands.sort(key=lambda x:x[0]);return cands[0][1],cands[0][2]
    def load_tcn_model_from_pt(self, path, device):
        try:
            sd=torch.load(path,map_location=device);
            if isinstance(sd,dict) and 'state_dict' in sd:sd=sd['state_dict']
            k,w=self._first_block_conv1_weight(sd);
            if w is None:raise RuntimeError('tcn.*.conv1.weight(_v) ì—†ìŒ')
            in_ch=w.shape[1];kernel=w.shape[2];blocks=[];
            for kk,vv in sd.items():
                if kk.endswith('conv1.weight_v') or kk.endswith('conv1.weight'):
                    try:idx=int(kk.split('.')[1]);blocks.append((idx,vv.shape[0]))
                    except:pass
            blocks.sort(key=lambda x:x[0]);num_channels=[b[1] for b in blocks];lin_w=sd.get('linear.weight',None);
            if lin_w is None:raise RuntimeError('linear.weight ì—†ìŒ')
            out_features=lin_w.shape[0];model=TCNModel(in_ch,num_channels,kernel,dropout=0.0,out_features=out_features);model.load_state_dict(sd,strict=False);model.to(device).eval();model.expected_in_ch=in_ch;model.out_features=out_features;print(f"[INFO] í†µí•© TCN ë¡œë“œ: {path} | in_ch={in_ch}, channels={num_channels}, kernel={kernel}, out={out_features}");return model
        except Exception as e:print(f"[ERROR] ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨({path}): {e}");return None
    def auto_select_reference_keys(self, key_list):
        sorted_keys=sorted(key_list,key=lambda k:k["center_x"]);leftmost=sorted_keys[0];rightmost=sorted_keys[-1];mid_candidates=sorted(key_list,key=lambda k:k["center_y"]);mid_key=sorted(mid_candidates,key=lambda k:abs(k["center_x"]-(leftmost["center_x"]+rightmost["center_x"])/2))[0];return [leftmost["label"],mid_key["label"],rightmost["label"]]
    def apply_transform_to_all_keys(self, ref_init, ref_curr, key_positions, reference_keys):
        if len(ref_init)<3 or len(ref_curr)<3:return key_positions
        init_pts=np.array([ref_init[k] for k in reference_keys],dtype=np.float32);curr_pts=np.array([ref_curr[k] for k in reference_keys],dtype=np.float32)
        M=cv2.getAffineTransform(init_pts,curr_pts);corrected=[]
        for key in key_positions:
            pt=np.array([[key['center_x'],key['center_y']]],dtype=np.float32);new_pt=cv2.transform(np.array([pt]),M)[0][0];corrected.append({"label":key["label"],"x":new_pt[0]-key["width"]/2,"y":new_pt[1]-key["height"]/2,"width":key["width"],"height":key["height"]})
        return corrected
    def extract_base_feature(self, landmarks):
        world=np.array([[p.x,p.y,p.z] for p in landmarks],dtype=np.float32);wr=world[0];rel=world-wr;sc=np.linalg.norm(rel[9]);
        if sc<1e-6:sc=1.0
        return (rel/sc).flatten()
    def predict_press(self, seq_vecs, model, device):
        if model is None:return None
        arr=np.asarray(seq_vecs,dtype=np.float32)
        if arr.ndim==1:arr=arr.reshape(arr.shape[0],-1)
        if arr.shape[1]!=getattr(model,'expected_in_ch',arr.shape[1]):
            if arr.shape[1]<model.expected_in_ch:pad=np.zeros((arr.shape[0],model.expected_in_ch-arr.shape[1]),dtype=np.float32);arr=np.concatenate([arr,pad],axis=1)
            else:arr=arr[:,:model.expected_in_ch]
        x=arr.reshape(1,SEQUENCE_LENGTH,-1);x=torch.from_numpy(x).permute(0,2,1).to(device)
        with torch.no_grad():out=model(x).squeeze()
        if out.ndim==0 or out.numel()==1:prob=torch.sigmoid(out).item()
        else:prob=torch.softmax(out,dim=-1)[1].item()
        return prob

    # [NEW] í‚¤ë³´ë“œ ì´ˆê¸° ì¸ì‹ ì „ìš© ë©”ì„œë“œ
    def setup_keyboard(self):
        while not self.captured_initial and self.running:
            frame = self.vs.read()
            if frame is None:
                time.sleep(0.01)
                continue

            frame = cv2.flip(frame, 1)
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            movement_amount = None

            if self.prev_gray is not None:
                diff = cv2.absdiff(self.prev_gray, gray)
                movement_amount = np.mean(diff)

                if movement_amount < MOVEMENT_THRESHOLD:
                    if self.stable_start_time is None: self.stable_start_time = time.time()
                    elif time.time() - self.stable_start_time >= STABLE_TIME_REQUIRED:
                        print("ğŸ“· ì•ˆì • ìƒíƒœ ê°ì§€. í‚¤ë³´ë“œ ìë™ ì¸ì‹ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                        det = self.keyboard_detector.predict(frame, verbose=False, device=self.device)[0]
                        temp_key_positions = []
                        for box in det.boxes:
                            lbl=det.names[int(box.cls[0])]; x1,y1,x2,y2=map(int,box.xyxy[0]); w0,h0=x2-x1,y2-y1; cx,cy=(x1+x2)/2,(y1+y2)/2
                            temp_key_positions.append({"label":lbl,"x":x1,"y":y1,"width":w0,"height":h0,"center_x":cx,"center_y":cy})

                        detected_count = len(temp_key_positions)
                        if detected_count in VALID_KEY_COUNTS:
                            self.initial_key_positions = temp_key_positions
                            self.reference_keys = self.auto_select_reference_keys(self.initial_key_positions)
                            for ki in self.initial_key_positions:
                                if ki["label"] in self.reference_keys: self.reference_initial[ki["label"]] = (ki["center_x"], ki["center_y"])
                            with self.lock:
                                self.corrected_boxes = [{"label":k["label"],"x":k["x"],"y":k["y"],"width":k["width"],"height":k["height"]} for k in self.initial_key_positions]

                            self.captured_initial = True
                            self.last_correction_time = time.time()
                            status_text = f"Reference Keys: {', '.join(self.reference_keys)}"
                            print(f"âœ… {detected_count}ê°œ í‚¤ ì¸ì‹ ì„±ê³µ! ê¸°ì¤€ í‚¤: {self.reference_keys}")
                            self.reference_keys_updated.emit(status_text)
                        else:
                            print(f"âŒ ì¸ì‹ ì‹¤íŒ¨ (ê°ì§€ëœ í‚¤ ê°œìˆ˜: {detected_count}).")
                            self.stable_start_time = None
                else:
                    self.stable_start_time = None

            self.prev_gray = gray.copy()
            cv2.putText(frame, "Waiting for keyboard to stabilize...", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            if movement_amount is not None: cv2.putText(frame, f"Movement: {movement_amount:.2f}", (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)

            self.new_frame.emit(frame) # UIì— í˜„ì¬ ìƒíƒœ í”„ë ˆì„ ì „ì†¡

            # â–¼â–¼â–¼ [ì¶”ê°€] UI ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ì‹œê°„ì„ ì¤ë‹ˆë‹¤. â–¼â–¼â–¼
            QApplication.processEvents()


    # [NEW] ì‹¤ì‹œê°„ íƒ€ì´í•‘ ì²˜ë¦¬ ì „ìš© ë©”ì„œë“œ
    def main_loop(self):
        with self.mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:
            while self.running:
                # â–¼â–¼â–¼ [ìˆ˜ì •] ì´ ifë¬¸ì„ ì¶”ê°€í•˜ì—¬ ì¬ì¸ì‹ ì‹ í˜¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤ â–¼â–¼â–¼
                if not self.captured_initial:
                    break # ì¬ì¸ì‹ ìƒíƒœê°€ ë˜ë©´ main_loopë¥¼ íƒˆì¶œ

                frame = self.vs.read()
                if frame is None:
                    time.sleep(0.01)
                    continue

                frame = cv2.flip(frame, 1)
                h, w, _ = frame.shape
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                now = time.time()
                now_ms = int(now * 1000)

                # ... (ì´í•˜ ëª¨ë“  ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¡œì§) ...
                if now - self.last_correction_time >= CORRECTION_INTERVAL_S:
                    det = self.keyboard_detector.predict(frame, verbose=False, device=self.device)[0]
                    if len(det.boxes) < RESET_KEY_COUNT_THRESHOLD:
                        print("ğŸš¨ í‚¤ë³´ë“œ ê°ì§€ ë¶ˆê°€! ì¦‰ì‹œ ì¬ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                        self.captured_initial=False
                        self.reference_keys_updated.emit("Reference Keys: N/A")
                        return # main_loopë¥¼ ì¢…ë£Œí•˜ê³  run ë©”ì„œë“œë¡œ ëŒì•„ê°€ setup_keyboardë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ê²Œ í•¨
                    else:
                        self.reference_current.clear()
                        for box in det.boxes:
                            lbl=det.names[int(box.cls[0])]; x1,y1,x2,y2=map(int,box.xyxy[0]); cx,cy=(x1+x2)/2,(y1+y2)/2
                            if lbl in self.reference_keys: self.reference_current[lbl]= (cx,cy)
                        if len(self.reference_current) >= 3:
                            corrected = self.apply_transform_to_all_keys(self.reference_initial, self.reference_current, self.initial_key_positions, self.reference_keys)
                            if corrected:
                                with self.lock: self.corrected_boxes = corrected
                        else:
                            print("[WARN] ë³´ì • ê¸°ì¤€ ë¶€ì¡± â†’ ì´ì „ ê°’ ìœ ì§€")
                    self.last_correction_time = now

                res = hands.process(rgb)
                # ... (ì´í•˜ ì† ì²˜ë¦¬, ì˜ˆì¸¡, í‚¤ ì…ë ¥, ê·¸ë¦¬ê¸° ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼) ...
                if res.multi_hand_landmarks:
                    for i, lm in enumerate(res.multi_hand_landmarks):
                        self.mp_drawing.draw_landmarks(frame, lm, self.mp_hands.HAND_CONNECTIONS)
                        base_vec = self.extract_base_feature(lm.landmark)
                        hand_label = 'Right' if (res.multi_handedness and res.multi_handedness[i].classification[0].label == 'Right') else 'Left'
                        self.seq_data[hand_label].append(base_vec)
                        tip = lm.landmark[8]
                        self.effect_xy[hand_label] = (int(tip.x * w), int(tip.y * h))
                else:
                    self.effect_xy['Right'] = self.effect_xy['Left'] = None

                if self.model is not None:
                    for hand_label in ('Right', 'Left'):
                        if len(self.seq_data[hand_label]) == SEQUENCE_LENGTH:
                            prob = self.predict_press(self.seq_data[hand_label], self.model, self.device) or 0.0
                            self.sm_prob[hand_label] = EMA_ALPHA * prob + (1.0 - EMA_ALPHA) * self.sm_prob[hand_label]
                            if not self.is_active[hand_label]:
                                if self.sm_prob[hand_label] >= self.PRED_ON_THRESH: self.on_cnt[hand_label] += 1
                                else: self.on_cnt[hand_label] = 0
                                if self.on_cnt[hand_label] >= MIN_ON_FRAMES: self.is_active[hand_label] = True; self.off_cnt[hand_label] = 0
                            else:
                                if self.sm_prob[hand_label] <= self.PRED_OFF_THRESH: self.off_cnt[hand_label] += 1
                                else: self.off_cnt[hand_label] = 0
                                if self.off_cnt[hand_label] >= MIN_OFF_FRAMES: self.is_active[hand_label] = False; self.on_cnt[hand_label] = 0
                        else:
                            self.is_active[hand_label] = False
                            self.on_cnt[hand_label] = self.off_cnt[hand_label] = 0

                for hand_label in ('Right', 'Left'):
                    if self.is_active[hand_label] and (not self.prev_active[hand_label]) and self.effect_xy[hand_label]:
                        if (now_ms - self.last_press_ms[hand_label]) >= max(DEBOUNCE_MS, self.REFRACTORY_MS):
                            x_, y_ = self.effect_xy[hand_label]
                            with self.lock: boxes_snapshot = self.corrected_boxes.copy()
                            for k in boxes_snapshot:
                                x0,y0,w0,h0=int(k['x']),int(k['y']),int(k['width']),int(k['height'])
                                if x0<=x_<=x0+w0 and y0<=y_<=y0+h0:
                                    mapped_key=key_name_map.get(k['label'],k['label'].lower())
                                    # â–¼â–¼â–¼ ì…ë ¥ í™œì„±í™” ìƒíƒœì¼ ë•Œë§Œ pyautogui.press ì‹¤í–‰ â–¼â–¼â–¼
                                    if self.input_enabled:
                                        pyautogui.press(mapped_key)
                                    now = time.time() # í˜„ì¬ ì‹œê°„ì„ ë‹¤ì‹œ ê°€ì ¸ì˜´
                                    self.last_pressed_info = {'key_label': k['label'], 'time': now}
                                    self.last_press_ms[hand_label] = now_ms
                                    print(f"[{time.strftime('%H:%M:%S')}] {hand_label} Pressed {mapped_key} | p_ema={self.sm_prob[hand_label]:.2f}")
                                    break
                    self.prev_active[hand_label] = self.is_active[hand_label]

                # (G) í™”ë©´ í‘œì‹œ
                right_state = "TYPING" if self.is_active['Right'] else "NOT TYPING"
                right_text = f"Right: {right_state} (p_ema={self.sm_prob['Right']:.2f})"
                left_state = "TYPING" if self.is_active['Left'] else "NOT TYPING"
                left_text = f"Left: {left_state} (p_ema={self.sm_prob['Left']:.2f})"
                combined_status = f"{right_text} | {left_text}"
                self.update_status.emit(combined_status)

                # â–¼â–¼â–¼ [ìˆ˜ì •] line_y ì •ì˜ ë° ê¸°ì¤€ í‚¤ ê·¸ë¦¬ê¸° ë¡œì§ (í™”ë©´ í‘œì‹œì˜ ì‹œì‘ ë¶€ë¶„ìœ¼ë¡œ ì´ë™) â–¼â–¼â–¼
                line_y=50
                if self.reference_keys:
                    # ì´ í…ìŠ¤íŠ¸ëŠ” ì´ì œ Worker ìŠ¤ë ˆë“œê°€ ì•„ë‹Œ MainWindowì˜ ìƒíƒœë°”ì— í‘œì‹œë©ë‹ˆë‹¤.
                    # cv2.putText(frame,f"Reference: {', '.join(reference_keys)}",(10,line_y),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2)
                    pass # ë‚˜ì¤‘ì— ë‹¤ë¥¸ ì •ë³´ë¥¼ í‘œì‹œí•  ìˆ˜ ìˆë„ë¡ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.

                with self.lock:
                    boxes_to_draw = self.corrected_boxes.copy()

                # â–¼â–¼â–¼ [ì¶”ê°€] í‚¤ ì…ë ¥ ì‹œê°ì  í”¼ë“œë°± ë¡œì§ â–¼â–¼â–¼
                # í‚¤ê°€ ëˆŒë ¸ì„ ë•Œ ì ê¹ ë™ì•ˆ ìƒ‰ì„ ë³€ê²½í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.
                # ì´ ë³€ìˆ˜ë“¤ì€ Workerì˜ __init__ì— ì¶”ê°€ë˜ì–´ì•¼ í•˜ì§€ë§Œ, ì„¤ëª…ì„ ìœ„í•´ ì—¬ê¸°ì— ë¡œì§ì„ ë¨¼ì € ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.
                # (ì‹¤ì œ êµ¬í˜„ ì‹œì—ëŠ” __init__ì— self.last_pressed_info = {'key': None, 'time': 0} ì¶”ê°€ í•„ìš”)

                for k in boxes_to_draw:
                    x0,y0,w0,h0=int(k['x']),int(k['y']),int(k['width']),int(k['height'])

                    # ê¸°ë³¸ ìƒ‰ìƒ ì„¤ì •
                    color=(0,255,255) if k['label'] in self.reference_keys else (0,255,0)

                    # í‚¤ ì…ë ¥ í”¼ë“œë°± í™•ì¸
                    # (self.last_pressed_infoëŠ” ë‚˜ì¤‘ì— __init__ì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤)
                    if hasattr(self, 'last_pressed_info') and k['label'] == self.last_pressed_info['key_label']:
                        if now - self.last_pressed_info['time'] < 0.2: # 0.2ì´ˆ ë™ì•ˆ ë…¸ë€ìƒ‰ìœ¼ë¡œ í‘œì‹œ
                            color = (255, 0, 0) # íŒŒë€ìƒ‰

                    cv2.rectangle(frame,(x0,y0),(x0+w0,y0+h0),color,1)

                    display_label = display_name_map.get(k['label'], k['label'])
                    cv2.putText(frame, display_label, (x0 + 5, y0 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)

                # â–¼â–¼â–¼ [ì¶”ê°€] í•‘ê±°íŒ ì»¤ì„œ ì‹œê°í™” ë¡œì§ â–¼â–¼â–¼
                for hand_label in ('Right', 'Left'):
                    if self.effect_xy[hand_label]:
                        center_coordinates = self.effect_xy[hand_label]
                        radius = 10
                        color = (0, 0, 255) # ë¹¨ê°„ìƒ‰
                        thickness = 0 # ì› ë‚´ë¶€ë¥¼ ë¹„ì›€
                        cv2.circle(frame, center_coordinates, radius, color, thickness)

                self.new_frame.emit(frame)

                # â–¼â–¼â–¼ [ì¶”ê°€] UI ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ì‹œê°„ì„ ì¤ë‹ˆë‹¤. â–¼â–¼â–¼
                QApplication.processEvents()

    # [NEW] run ë©”ì„œë“œì˜ ìƒˆë¡œìš´ êµ¬ì¡°
    def run(self):
        self.apply_preset("Balanced")
        while self.running:
            self.setup_keyboard()
            if not self.running: break # ì‚¬ìš©ìê°€ setup ë„ì¤‘ ì¢…ë£Œ ì‹œ
            self.main_loop()
        self.finished.emit()

    def stop(self):
        self.running = False

# ===== MainWindow í´ë˜ìŠ¤ (UI ë ˆì´ì•„ì›ƒ í™•ì¥) =====
class MainWindow(QMainWindow):
    # â–¼â–¼â–¼ Workerì—ê²Œ ë³´ë‚¼ ì‹ í˜¸ ì¶”ê°€ (bool íƒ€ì…ì˜ ë°ì´í„°ë¥¼ ì „ë‹¬) â–¼â–¼â–¼
    toggle_input_signal = Signal(bool)
    rerecognize_signal = Signal()    # ì¬ì¸ì‹ ì‹ í˜¸ ì¶”ê°€
    apply_preset_signal = Signal(str) # í”„ë¦¬ì…‹ ì ìš© ì‹ í˜¸ ì¶”ê°€

    def __init__(self):
        super().__init__()
        self.setWindowTitle("AI Virtual Keyboard")
        self.setGeometry(100, 100, 1366, 768) # ì°½ í¬ê¸°ë¥¼ ì•½ê°„ ë” ë„“ê²Œ ì„¤ì •
        self.center() # ì°½ì„ í™”ë©´ ì¤‘ì•™ìœ¼ë¡œ ì´ë™ì‹œí‚¤ëŠ” ë©”ì„œë“œ í˜¸ì¶œ

        # --- [ì¶”ê°€] ë‹¤í¬/ë¼ì´íŠ¸ ëª¨ë“œ ìŠ¤íƒ€ì¼ì‹œíŠ¸ ì •ì˜ ---
        self.light_mode_style = """
            QMainWindow { background-color: #f0f0f0; }
            QLabel { color: black; }
            QPushButton { background-color: #e0e0e0; color: black; border: 1px solid #b0b0b0; padding: 5px; }
            QPushButton:hover { background-color: #d0d0d0; }
            QMenuBar { background-color: #e0e0e0; color: black; }
            QMenuBar::item:selected { background-color: #d0d0d0; }
            QMenu { background-color: #f0f0f0; color: black; }
            QMenu::item:selected { background-color: #d0d0d0; }
        """
        self.dark_mode_style = """
            QMainWindow { background-color: #2b2b2b; }
            QLabel { color: white; }
            QPushButton { background-color: #505050; color: white; border: 1px solid #606060; padding: 5px; }
            QPushButton:hover { background-color: #606060; }
            QMenuBar { background-color: #3c3c3c; color: white; }
            QMenuBar::item:selected { background-color: #505050; }
            QMenu { background-color: #3c3c3c; color: white; }
            QMenu::item:selected { background-color: #505050; }
            QStatusBar { color: white; }
        """

        # --- [ì¶”ê°€] ë©”ë‰´ë°” ìƒì„± ---
        menu_bar = self.menuBar()

        # Preset ë©”ë‰´
        preset_menu = menu_bar.addMenu("Preset")
        # functools.partialì„ ì‚¬ìš©í•˜ì—¬ ê° ë©”ë‰´ ì•¡ì…˜ì— ë‹¤ë¥¸ ì¸ìë¥¼ ì „ë‹¬
        # í”„ë¦¬ì…‹ ë²„íŠ¼ ì¶”ê°€
        from functools import partial
        sensitive_action = preset_menu.addAction("Sensitive")
        sensitive_action.triggered.connect(partial(self.apply_preset, "Sensitive"))
        balanced_action = preset_menu.addAction("Balanced")
        balanced_action.triggered.connect(partial(self.apply_preset, "Balanced"))
        stable_action = preset_menu.addAction("Stable")
        stable_action.triggered.connect(partial(self.apply_preset, "Stable"))
        # very_stable_action = preset_menu.addAction("Very Stable")
        # very_stable_action.triggered.connect(partial(self.apply_preset, "Very Stable"))

        # ViewMode ë©”ë‰´
        view_menu = menu_bar.addMenu("ViewMode")
        dark_mode_action = view_menu.addAction("Dark Mode")
        light_mode_action = view_menu.addAction("Light Mode")

        dark_mode_action.triggered.connect(self.set_dark_mode)
        light_mode_action.triggered.connect(self.set_light_mode)

        # --- [ìˆ˜ì •] ë©”ì¸ ë ˆì´ì•„ì›ƒ êµ¬ì¡° ---
        self.central_widget = QWidget()
        self.setCentralWidget(self.central_widget)
        self.main_layout = QVBoxLayout(self.central_widget)

        # 1. ìƒë‹¨ ë ˆì´ì•„ì›ƒ (í•˜ë“œì›¨ì–´ ì •ë³´, í”„ë¦¬ì…‹ ì •ë³´)
        top_layout = QHBoxLayout()
        self.hw_info_label = QLabel(f"CPU: {cpu_name}<br>GPU: {gpu_name}", self)
        top_layout.addWidget(self.hw_info_label)

        top_layout.addStretch(1)
        self.preset_info_label = QLabel("Preset: N/A", self)
        self.preset_info_label.setAlignment(Qt.AlignRight | Qt.AlignTop)
        top_layout.addWidget(self.preset_info_label)

        # 2. ì¤‘ì•™ ë ˆì´ì•„ì›ƒ (ë²„íŠ¼ + ìº  í™”ë©´ + ë²„íŠ¼)
        center_layout = QHBoxLayout()
        self.toggle_button = QPushButton("Input ON/OFF", self)
        self.rerecognize_button = QPushButton("Re-recognize\n Keyboard", self)
        # ì´ ìˆ«ìë¥¼ ì¡°ì ˆí•˜ì—¬ ì›í•˜ëŠ” ë„ˆë¹„ë¡œ ë§ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        fixed_button_width = 150
        self.toggle_button.setFixedWidth(fixed_button_width)
        self.rerecognize_button.setFixedWidth(fixed_button_width)
        self.video_label = QLabel("Initializing...", self)
        self.video_label.setAlignment(Qt.AlignCenter)
        center_layout.addWidget(self.toggle_button)
        center_layout.addWidget(self.video_label, 1)
        center_layout.addWidget(self.rerecognize_button)

        # ë©”ì¸ ë ˆì´ì•„ì›ƒì— ìœ„ì ¯ê³¼ ë ˆì´ì•„ì›ƒ ì¶”ê°€
        self.main_layout.addLayout(top_layout)
        self.main_layout.addStretch(1) # ì¤‘ì•™ ë ˆì´ì•„ì›ƒ ìœ„ìª½ ë¹ˆ ê³µê°„
        self.main_layout.addLayout(center_layout)
        self.main_layout.addStretch(1) # ì¤‘ì•™ ë ˆì´ì•„ì›ƒ ì•„ë˜ìª½ ë¹ˆ ê³µê°„

        # --- ìƒíƒœë°” ë° ìŠ¤ë ˆë“œ ì„¤ì • (ê¸°ì¡´ê³¼ ìœ ì‚¬) ---
        self.status_bar = self.statusBar()
        self.status_bar.showMessage("Initializing hardware...")
        self.ref_keys_label = QLabel("Reference Keys: N/A", self)
        self.status_bar.addPermanentWidget(self.ref_keys_label)

        self.set_light_mode() # ê¸°ë³¸ ëª¨ë“œë¥¼ ë¼ì´íŠ¸ ëª¨ë“œë¡œ ì„¤ì •

        # 1. UI ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.input_enabled = True

        # 2. ë²„íŠ¼ í´ë¦­ê³¼ ìŠ¬ë¡¯ í•¨ìˆ˜ ì—°ê²°
        self.toggle_button.clicked.connect(self.toggle_input)
        self.rerecognize_button.clicked.connect(self.force_rerecognize)

        # â–¼â–¼â–¼ [ìˆ˜ì •] ì¹´ë©”ë¼ ìë™ ì „í™˜ ë¡œì§ ì¶”ê°€ â–¼â–¼â–¼
        try:
            if USE_NETWORK_CAM:
                # 1. ë„¤íŠ¸ì›Œí¬ ì¹´ë©”ë¼ë¥¼ ìš°ì„  ì‹œë„
                self.vs = VideoStream(src=NETWORK_CAM_URL)
            else:
                # ì„¤ì •ì´ Falseë©´ ì²˜ìŒë¶€í„° ë¡œì»¬ ì›¹ìº  ì‹œë„
                self.vs = VideoStream(src=0)
        except IOError:
            # 2. ìœ„ì—ì„œ IOError ë°œìƒ ì‹œ (ì—°ê²° ì‹¤íŒ¨ ì‹œ) ì—¬ê¸°ë¡œ ë„˜ì–´ì˜´
            print("[WARN] Primary camera failed. Falling back to local webcam...")
            try:
                # 3. ë¡œì»¬ ì›¹ìº (0ë²ˆ)ìœ¼ë¡œ ë‹¤ì‹œ ì—°ê²° ì‹œë„
                self.vs = VideoStream(src=0)
            except IOError as e:
                # 4. ëª¨ë“  ì¹´ë©”ë¼ ì—°ê²°ì— ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬ íŒì—…ì°½ì„ ë„ìš°ê³  ì¢…ë£Œ
                error_title = "Camera Connection Failed"
                error_message = ("Could not connect to network or local webcam.\n\n"
                                "Please check your camera connection and restart the application.")
                QMessageBox.critical(self, error_title, error_message)
                sys.exit() # ì‚¬ìš©ìê°€ "OK"ë¥¼ ëˆ„ë¥´ë©´ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
        self.thread = QThread()
        self.worker = Worker(self.vs)
        self.worker.moveToThread(self.thread)

        # 4. ëª¨ë“  ì‹ í˜¸-ìŠ¬ë¡¯ ì—°ê²°
        # Worker -> MainWindow
        self.worker.new_frame.connect(self.update_video_label)
        self.worker.update_status.connect(self.update_status_bar)
        self.worker.reference_keys_updated.connect(self.update_ref_keys_label)
        # MainWindow -> Worker
        self.toggle_input_signal.connect(self.worker.set_input_enabled)
        self.rerecognize_signal.connect(self.worker.force_rerecognize)
        self.apply_preset_signal.connect(self.worker.apply_preset)
        # â–¼â–¼â–¼ í”„ë¦¬ì…‹ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹ í˜¸-ìŠ¬ë¡¯ ì—°ê²° ì¶”ê°€ â–¼â–¼â–¼
        self.worker.preset_updated_signal.connect(self.update_preset_display)

        # ìŠ¤ë ˆë“œ ìƒëª…ì£¼ê¸°
        self.thread.started.connect(self.worker.run)
        self.worker.finished.connect(self.thread.quit)
        self.worker.finished.connect(self.worker.deleteLater)
        self.thread.finished.connect(self.thread.deleteLater)

        # 5. ìŠ¤ë ˆë“œ ì‹œì‘ ë° ì°½ ì¤‘ì•™ ë°°ì¹˜
        self.thread.start()
        self.center()
        
    def center(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì°½ì„ í™”ë©´ ì¤‘ì•™ì— ë°°ì¹˜í•©ë‹ˆë‹¤."""
        screen_geometry = self.screen().geometry()
        window_geometry = self.frameGeometry()
        window_geometry.moveCenter(screen_geometry.center())
        self.move(window_geometry.topLeft())

    # â–¼â–¼â–¼ [ì¶”ê°€] í† ê¸€ ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰ë  ìŠ¬ë¡¯ â–¼â–¼â–¼
    def toggle_input(self):
        # 1. UIì˜ ìƒíƒœ ë³€ìˆ˜ë¥¼ ë°˜ì „ì‹œí‚´
        self.input_enabled = not self.input_enabled

        # 2. ë²„íŠ¼ í…ìŠ¤íŠ¸ë¥¼ í˜„ì¬ ìƒíƒœì— ë§ê²Œ ë³€ê²½
        if self.input_enabled:
            self.toggle_button.setText("Input: ON")
        else:
            self.toggle_button.setText("Input: OFF")

        # 3. Worker ìŠ¤ë ˆë“œì—ê²Œ ë³€ê²½ëœ ìƒíƒœë¥¼ ì‹ í˜¸ë¡œ ë³´ëƒ„
        self.toggle_input_signal.emit(self.input_enabled)

    def force_rerecognize(self):
        """ì¬ì¸ì‹ ë²„íŠ¼ í´ë¦­ ì‹œ Workerì—ê²Œ ì‹ í˜¸ë¥¼ ë³´ëƒ…ë‹ˆë‹¤."""
        self.rerecognize_signal.emit()

    def apply_preset(self, preset_name):
        """í”„ë¦¬ì…‹ ë©”ë‰´ ì„ íƒ ì‹œ Workerì—ê²Œ í”„ë¦¬ì…‹ ì´ë¦„ì„ ì‹ í˜¸ë¡œ ë³´ëƒ…ë‹ˆë‹¤."""
        self.apply_preset_signal.emit(preset_name)
        self.status_bar.showMessage(f"Preset changed to: {preset_name}", 2000)

    # â–¼â–¼â–¼ í”„ë¦¬ì…‹ ì •ë³´ í‘œì‹œë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ìŠ¬ë¡¯ ì¶”ê°€ â–¼â–¼â–¼
    def update_preset_display(self, name, on, off, ema):
        text = f"Preset: {name}\nON:{on:.2f} OFF:{off:.2f} EMA:{ema:.2f}"
        self.preset_info_label.setText(text)

    def update_video_label(self, frame):
        h, w, ch = frame.shape
        bytes_per_line = ch * w
        qt_image = QImage(frame.data, w, h, bytes_per_line, QImage.Format_BGR888)
        pixmap = QPixmap.fromImage(qt_image)
        self.video_label.setPixmap(pixmap)

    def update_status_bar(self, full_status_text):
        self.status_bar.showMessage(full_status_text)

    def update_ref_keys_label(self, text):
        self.ref_keys_label.setText(text)

    # MainWindow í´ë˜ìŠ¤ ë‚´ë¶€ (ì˜ˆ: update_ref_keys_label ë©”ì„œë“œ ë‹¤ìŒ)
    def update_preset_display(self, text):
        """Workerë¡œë¶€í„° ë°›ì€ í”„ë¦¬ì…‹ ì •ë³´ë¡œ ë¼ë²¨ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        self.preset_info_label.setText(text)

    # --- [ì¶”ê°€] ë‹¤í¬/ë¼ì´íŠ¸ ëª¨ë“œ ì „í™˜ì„ ìœ„í•œ ìŠ¬ë¡¯ ---
    def set_dark_mode(self):
        self.setStyleSheet(self.dark_mode_style)

    def set_light_mode(self):
        self.setStyleSheet(self.light_mode_style)

    def closeEvent(self, event):
        print("Stopping threads...")
        self.worker.stop()
        self.vs.stop()
        event.accept()

# ===== í”„ë¡œê·¸ë¨ ì‹¤í–‰ë¶€ =====
# if __name__ == "__main__":
#    pyautogui.FAILSAFE = False
#    app = QApplication(sys.argv)
#    window = MainWindow()
#    window.show()
#    sys.exit(app.exec())

# ===== í”„ë¡œê·¸ë¨ ì‹¤í–‰ë¶€ (ìŠ¤í”Œë˜ì‹œ ìŠ¤í¬ë¦° ì ìš©) =====
if __name__ == "__main__":
    pyautogui.FAILSAFE = False
    app = QApplication(sys.argv)

    # 1. ìŠ¤í”Œë˜ì‹œ ìŠ¤í¬ë¦°ì— ì‚¬ìš©í•  ì´ë¯¸ì§€(Pixmap) ìƒì„±
    splash_pix = QPixmap("logo.png")

    # â–¼â–¼â–¼ [ìˆ˜ì •] ì›í•˜ëŠ” í¬ê¸°(ì˜ˆ: ë„ˆë¹„ 000px)ë¡œ ì¡°ì •í•©ë‹ˆë‹¤ â–¼â–¼â–¼
    # ë†’ì´ëŠ” ë¹„ìœ¨ì— ë§ê²Œ ìë™ ì¡°ì ˆë©ë‹ˆë‹¤. ìˆ«ìë¥¼ ë°”ê¿”ì„œ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.
    scaled_pix = splash_pix.scaledToWidth(300, Qt.SmoothTransformation)

    # ì¡°ì •ëœ ì´ë¯¸ì§€(scaled_pix)ë¡œ ìŠ¤í”Œë˜ì‹œ ìŠ¤í¬ë¦° ìƒì„±
    splash = QSplashScreen(scaled_pix, Qt.WindowStaysOnTopHint)

    # ... (ì´í•˜ ìŠ¤í”Œë˜ì‹œ ìŠ¤í¬ë¦° ë¡œì§ì€ ë™ì¼) ...
    splash.show()
    splash.showMessage("Loading AI models...", Qt.AlignBottom | Qt.AlignCenter, Qt.white)
    window = MainWindow()
    splash.finish(window)
    window.show()

    sys.exit(app.exec())