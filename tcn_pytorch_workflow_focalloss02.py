# -*- coding: utf-8 -*-
"""TCN_pytorch_workflow_Focalloss02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17auX5NwS0FjdptJNhXJvWLqEBbcGIHia
"""

# ##############################################################################
# @title 셀 1 (Focal Loss용): 기본 설정 및 라이브러리 임포트
# ##############################################################################
from google.colab import files
import os
import glob
import pandas as pd
import numpy as np
from collections import Counter

import torch
import torch.nn as nn
import torch.nn.functional as F # Focal Loss 구현에 필요
from torch.utils.data import Dataset, DataLoader

from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score

# 재현성을 위한 시드 고정
SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# GPU 사용 설정
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"사용 디바이스: {device}")
print("-" * 50)

# 하이퍼파라미터 설정
class Config:
    # --- 데이터 관련 ---
    SEQUENCE_LENGTH = 20

    # --- 훈련 관련 ---
    OPTIMIZER = 'AdamW'
    LEARNING_RATE = 1e-4
    BATCH_SIZE = 64
    EPOCHS = 50 # 단일 훈련이므로 에포크 수를 충분히 설정

    # --- Focal Loss 파라미터 (보고서 표 4와 별개) ---
    # alpha: 클래스 가중치. 소수 클래스(1)에 더 높은 가중치를 부여하여 불균형을 조절합니다.
    # 일반적으로 0.25 또는 (1 - 소수 클래스 비율) 등을 사용하며, 튜닝 대상입니다.
    FOCAL_LOSS_ALPHA = 0.25
    # gamma: Focusing 파라미터. 모델이 이미 잘 맞히는 '쉬운' 샘플의 손실은 줄이고,
    # 맞히기 '어려운' 샘플에 더 집중하도록 만듭니다. 2~5 사이의 값을 주로 사용합니다.
    FOCAL_LOSS_GAMMA = 2

    # --- 모델 아키텍처 관련 (TCN) ---
    TCN_INPUT_CHANNELS = -1
    TCN_NUM_CHANNELS = [256] * 2
    TCN_KERNEL_SIZE = 3
    DROPOUT = 0.2

# 설정값 인스턴스 생성
config = Config()

# ##############################################################################
# @title 셀 2 (Focal Loss용): Focal Loss 함수 정의
# ##############################################################################

class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        """
        Args:
            inputs: 모델의 예측 로짓 (Batch, Num_Classes)
            targets: 실제 레이블 (Batch,)
        """
        # 표준 Cross Entropy Loss 계산
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')

        # 예측된 클래스의 확률(pt) 계산 (pt = e^(-ce_loss))
        pt = torch.exp(-ce_loss)

        # Focal Loss 계산: (1-pt)^gamma * ce_loss
        focal_loss = ((1 - pt) ** self.gamma) * ce_loss

        # Alpha 가중치 적용 (선택 사항)
        if self.alpha is not None:
            # targets 텐서와 동일한 디바이스 및 타입으로 alpha_t 텐서 생성
            alpha_t = torch.full_like(targets, 1 - self.alpha, device=targets.device, dtype=torch.float32)
            # targets 값이 1인 위치에 alpha 값을 적용
            alpha_t[targets == 1] = self.alpha
            focal_loss = alpha_t * focal_loss

        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

print("FocalLoss 클래스가 정의되었습니다.")

# ##############################################################################
# @title 셀 2 (통합 모델용): 데이터 로딩 (양손 통합) - 수정된 버전
# ##############################################################################
import os
import glob
import pandas as pd
import numpy as np
from collections import Counter
from google.colab import drive

# 1. Google Drive 마운트
# 이미 마운트된 경우를 대비해 try-except 구문 사용
try:
    drive.mount('/content/drive')
except Exception as e:
    print(f"Drive 마운트 중 오류 발생 또는 이미 마운트됨: {e}")

# 2. 데이터 경로 설정
# 데이터가 저장된 최상위 폴더를 지정합니다.
# 예: /content/drive/MyDrive/gesture_data_v3
BASE_DATA_DIR = '/content/drive/MyDrive/gesture_data_v3'

# 3. 모든 하위 폴더에서 CSV 파일 검색
# BASE_DATA_DIR 아래의 모든 폴더(**/)에 있는 모든 csv파일(*.csv)을 찾습니다.
FILE_PATTERN = os.path.join(BASE_DATA_DIR, '**', '*.csv')

print(f"'{FILE_PATTERN}' 패턴으로 파일 검색 중...")
# recursive=True 옵션으로 모든 하위 폴더를 탐색합니다.
all_files = glob.glob(FILE_PATTERN, recursive=True)

# 4. 파일 존재 여부 확인 및 데이터 로딩
if not all_files:
    print(f"\n[오류] '{FILE_PATTERN}' 패턴과 일치하는 파일을 찾을 수 없습니다.")
    print("아래 사항을 확인해주세요:")
    print(f"1. Google Drive가 '/content/drive'에 올바르게 마운트되었는지 확인")
    print(f"2. 기본 경로 '{BASE_DATA_DIR}'가 존재하는지 확인")
    print(f"3. 해당 경로 및 하위 폴더에 '.csv' 확장자를 가진 파일이 있는지 확인")
else:
    print(f"\n총 {len(all_files)}개의 CSV 파일을 발견했습니다. 데이터 로딩을 시작합니다.")
    try:
        # 5. 모든 CSV 파일을 하나로 합치기
        df_list = [pd.read_csv(f) for f in all_files]
        combined_df = pd.concat(df_list, ignore_index=True)
        print(f"\n총 {len(all_files)}개의 파일에서 {len(combined_df)}개의 프레임 데이터를 성공적으로 불러왔습니다.")
        print(f"초기 레이블 분포:\n{combined_df['label'].value_counts()}\n")

        # 6. 피처(X)와 레이블(y) 분리 및 타입 변환
        X_raw = combined_df.drop('label', axis=1).values
        y_raw = combined_df['label'].values.astype(int)

        # 7. 시퀀스 데이터 생성 함수 (config.SEQUENCE_LENGTH가 미리 정의되어 있어야 함)
        # 예시: config 객체가 없으면 여기서 임시 정의
        # class Config: SEQUENCE_LENGTH = 10
        # config = Config()
        def create_sequences(X, y, sequence_length):
            X_seq, y_seq = [], []
            for i in range(len(X) - sequence_length + 1):
                X_seq.append(X[i:i + sequence_length])
                y_seq.append(y[i + sequence_length - 1])
            return np.array(X_seq), np.array(y_seq)

        # 8. 시퀀스 데이터 생성 실행
        # 아래 코드 실행 전 'config.SEQUENCE_LENGTH' 값이 정의되어 있어야 합니다.
        X_sequences, y_sequences = create_sequences(X_raw, y_raw, config.SEQUENCE_LENGTH)

        # 9. 모델의 입력 채널 수를 동적으로 설정
        # 아래 코드 실행 전 'config' 객체가 정의되어 있어야 합니다.
        config.TCN_INPUT_CHANNELS = X_sequences.shape[2]

        print("시퀀스 데이터 생성 완료!")
        print(f"X 형태: {X_sequences.shape}")
        print(f"y 형태: {y_sequences.shape}")
        print(f"변환 후 레이블 분포: {Counter(y_sequences)}")
        print(f"모델 입력 채널 수 (config.TCN_INPUT_CHANNELS): {config.TCN_INPUT_CHANNELS}")

    except Exception as e:
        print(f"\n[오류] 데이터 처리 중 문제가 발생했습니다: {e}")
        print("CSV 파일 형식이 모두 동일한지, 모든 파일에 'label' 열이 존재하는지 확인해주세요.")

# ##############################################################################
# @title 셀 3 (통합 모델용): 데이터 증강 (좌우 반전 추가)
# ##############################################################################

def augment_horizontal_flip(sequence: np.ndarray) -> np.ndarray:
    """
    랜드마크 시퀀스를 Y-Z 평면(x=0)을 기준으로 좌우 반전시킵니다.
    x 좌표에 -1을 곱하여 간단히 구현합니다.
    """
    flipped_sequence = sequence.copy()
    # x 좌표는 3개마다 하나씩 위치 (x0, y0, z0, x1, y1, z1, ...)
    # [:, ::3]는 모든 프레임에 대해, 0번 feature부터 3칸씩 건너뛰며 선택
    flipped_sequence[:, ::3] = -1 * flipped_sequence[:, ::3]
    return flipped_sequence

def augment_rotate(sequence: np.ndarray, max_angle_deg: float = 10.0) -> np.ndarray:
    # (이전과 동일한 코드)
    original_shape = sequence.shape
    if original_shape[1] % 3 != 0: return sequence
    num_points = original_shape[1] // 3
    sequence_reshaped = sequence.reshape(original_shape[0], num_points, 3)
    angle_rad = np.random.uniform(-max_angle_deg, max_angle_deg) * (np.pi / 180.0)
    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)
    rotation_matrix = np.array([[cos_a, -sin_a, 0], [sin_a, cos_a, 0], [0, 0, 1]])
    rotated_sequence_reshaped = np.dot(sequence_reshaped, rotation_matrix)
    return rotated_sequence_reshaped.reshape(original_shape)

def augment_scale(sequence: np.ndarray, min_scale: float = 0.9, max_scale: float = 1.1) -> np.ndarray:
    # (이전과 동일한 코드)
    scale = np.random.uniform(min_scale, max_scale)
    return sequence * scale

def augment_jitter(sequence: np.ndarray, std: float = 0.01) -> np.ndarray:
    # (이전과 동일한 코드)
    noise = np.random.normal(loc=0.0, scale=std, size=sequence.shape)
    return sequence + noise

# --- 온라인 증강을 적용하는 Custom Dataset 클래스 ---
class GestureDataset(Dataset):
    def __init__(self, X, y, sequence_length, apply_augmentations=False):
        self.X = X
        self.y = y
        self.sequence_length = sequence_length
        self.apply_augmentations = apply_augmentations

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        x_item = self.X[idx].copy()
        y_item = self.y[idx]

        if self.apply_augmentations:
            # [핵심 변경점] 50% 확률로 좌우 반전 증강을 먼저 적용
            if np.random.random() < 0.5:
                x_item = augment_horizontal_flip(x_item)

            # 기존의 공간적 증강들을이어서 적용
            x_item = augment_rotate(x_item)
            x_item = augment_scale(x_item)
            x_item = augment_jitter(x_item)

        x_tensor = torch.FloatTensor(x_item)
        y_tensor = torch.LongTensor([y_item]).squeeze()

        return x_tensor, y_tensor

print("데이터 증강 함수 및 Custom Dataset 클래스가 정의되었습니다. (좌우 반전 추가 완료)")

# ##############################################################################
# @title 셀 4 (수정됨): TCN 모델 아키텍처 정의
# ##############################################################################

class TemporalBlock(nn.Module):
    """
    TCN의 기본 구성 요소인 Temporal Block입니다.
    [수정 사항] 컨볼루션 이후 시퀀스 길이를 원본과 동일하게 맞추기 위해 슬라이싱 로직을 추가합니다.
    """
    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):
        super(TemporalBlock, self).__init__()
        # nn.utils.weight_norm을 conv 레이어에 직접 적용합니다.
        self.conv1 = nn.utils.weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,
                                           stride=stride, padding=padding, dilation=dilation))
        self.padding1 = padding # 슬라이싱에 사용할 패딩 값을 저장
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(dropout)

        self.conv2 = nn.utils.weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,
                                           stride=stride, padding=padding, dilation=dilation))
        self.padding2 = padding # 슬라이싱에 사용할 패딩 값을 저장
        self.relu2 = nn.ReLU()
        self.dropout2 = nn.Dropout(dropout)

        # 다운샘플링 레이어는 입력과 출력의 채널 수가 다를 때 사용됩니다.
        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None
        self.relu = nn.ReLU()

    def forward(self, x):
        # x: (Batch, Channels, Seq_Len)

        # 첫 번째 컨볼루션 블록
        out = self.conv1(x)
        # 늘어난 패딩만큼 끝부분을 잘라내어 길이를 맞춤 (Causal Convolution)
        out = out[:, :, :-self.padding1]
        out = self.relu1(out)
        out = self.dropout1(out)

        # 두 번째 컨볼루션 블록
        out = self.conv2(out)
        out = out[:, :, :-self.padding2]
        out = self.relu2(out)
        out = self.dropout2(out)

        # 잔차 연결 (Residual Connection)
        res = x if self.downsample is None else self.downsample(x)

        # 이제 out과 res의 시퀀스 길이가 동일하므로 덧셈이 가능합니다.
        return self.relu(out + res)


class TCN(nn.Module):
    """
    Temporal Convolutional Network 모델입니다.
    보고서 표 4의 하이퍼파라미터를 사용하여 구성됩니다.
    """
    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):
        super(TCN, self).__init__()
        layers = []
        num_levels = len(num_channels)
        for i in range(num_levels):
            dilation_size = 2 ** i
            in_channels = input_size if i == 0 else num_channels[i-1]
            out_channels = num_channels[i]
            # 인과적 컨볼루션을 위한 패딩 계산
            padding = (kernel_size - 1) * dilation_size
            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,
                                     padding=padding, dropout=dropout)]

        self.tcn = nn.Sequential(*layers)
        self.linear = nn.Linear(num_channels[-1], output_size)

    def forward(self, x):
        # 입력: (Batch, Seq_Len, Features)
        # TCN은 (Batch, Features, Seq_Len) 형태를 기대하므로 차원 변경
        x = x.permute(0, 2, 1)

        out = self.tcn(x)

        # 마지막 타임스텝의 출력만 사용하여 분류
        out = self.linear(out[:, :, -1])
        return out

print("TCN 모델 아키텍처가 정의되었습니다. (수정 완료)")

# ##############################################################################
# @title 셀 5: 훈련 및 평가 함수 정의
# ##############################################################################
from tqdm.auto import tqdm # 진행 상황을 시각적으로 보여주는 라이브러리

def train_one_epoch(model, data_loader, criterion, optimizer, device):
    """한 에포크 동안 모델을 훈련시키는 함수"""
    model.train()
    total_loss = 0

    for inputs, labels in tqdm(data_loader, desc="Training", leave=False):
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(data_loader)

def evaluate(model, data_loader, criterion, device):
    """모델의 성능을 평가하는 함수"""
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in tqdm(data_loader, desc="Evaluating", leave=False):
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            total_loss += loss.item()

            preds = torch.argmax(outputs, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    avg_loss = total_loss / len(data_loader)

    # 보고서에서 권장하는 F1-Score를 포함한 평가지표 계산 [cite: 91]
    metrics = {
        'loss': avg_loss,
        'f1_score': f1_score(all_labels, all_preds, average='binary'),
        'accuracy': accuracy_score(all_labels, all_preds),
        'precision': precision_score(all_labels, all_preds, average='binary'),
        'recall': recall_score(all_labels, all_preds, average='binary')
    }

    return metrics

print("훈련 및 평가 함수가 정의되었습니다.")

# ##############################################################################
# @title 최종 실행 셀 (Focal Loss용): 🚀 모델 훈련 실행
# ##############################################################################
print("--- Focal Loss 기반 TCN 모델 훈련 시작 ---")

# 이 셀을 실행하기 전에, 이전 TCN 워크플로우의
# [셀 2: 데이터 로드], [셀 3: 데이터 증강], [셀 4: TCN 모델 정의], [셀 5: 훈련/평가 함수]가
# 먼저 실행되어 있어야 합니다.

# 1. 원본 불균형 데이터셋으로 훈련/검증 데이터 분리
# T-SMOTE를 사용하지 않으므로, 원본 시퀀스 데이터를 바로 사용합니다.
X_train, X_val, y_train, y_val = train_test_split(
    X_sequences, y_sequences,
    test_size=0.2,
    random_state=SEED,
    stratify=y_sequences # 불균형 데이터이므로 stratify가 중요
)

# 2. 훈련용/검증용 Dataset 및 DataLoader 생성 (공간 증강 적용)
train_dataset = GestureDataset(X_train, y_train, config.SEQUENCE_LENGTH, apply_augmentations=True)
val_dataset = GestureDataset(X_val, y_val, config.SEQUENCE_LENGTH, apply_augmentations=False)
train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False)
print(f"훈련 데이터: {len(train_dataset)}개, 검증 데이터: {len(val_dataset)}개")

# 3. TCN 모델, Focal Loss, 옵티마이저 정의
model = TCN(
    input_size=config.TCN_INPUT_CHANNELS,
    output_size=2,
    num_channels=config.TCN_NUM_CHANNELS,
    kernel_size=config.TCN_KERNEL_SIZE,
    dropout=config.DROPOUT
).to(device)

# [핵심 변경 사항] CrossEntropyLoss 대신 FocalLoss를 손실 함수로 사용합니다.
criterion = FocalLoss(alpha=config.FOCAL_LOSS_ALPHA, gamma=config.FOCAL_LOSS_GAMMA)
optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)

print("\n모델 아키텍처:")
print(model)
print(f"\n손실 함수: FocalLoss (alpha={config.FOCAL_LOSS_ALPHA}, gamma={config.FOCAL_LOSS_GAMMA})")
print(f"총 {config.EPOCHS} 에포크 동안 훈련을 시작합니다...")

# 4. 훈련 루프 실행
best_f1_score = 0.0
FOCAL_LOSS_MODEL_PATH = 'focal_loss_model_tcn.pt'

for epoch in range(config.EPOCHS):
    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)
    val_metrics = evaluate(model, val_loader, criterion, device)

    print(
        f"Epoch {epoch+1}/{config.EPOCHS} | "
        f"Train Loss: {train_loss:.4f} | "
        f"Val Loss: {val_metrics['loss']:.4f} | "
        f"Val F1: {val_metrics['f1_score']:.4f} | "
        f"Val Acc: {val_metrics['accuracy']:.4f}"
    )

    # 검증 F1-score가 가장 높은 모델을 최종 모델로 저장
    if val_metrics['f1_score'] > best_f1_score:
        best_f1_score = val_metrics['f1_score']
        torch.save(model.state_dict(), FOCAL_LOSS_MODEL_PATH)
        print(f"  -> 🎉 New best model saved with F1-Score: {best_f1_score:.4f}")

print("-" * 50)
print(f"✅ 훈련 완료: Focal Loss 모델이 '{FOCAL_LOSS_MODEL_PATH}'에 성공적으로 저장되었습니다.")
print(f"최고 검증 F1-Score: {best_f1_score:.4f}")
files.download(FOCAL_LOSS_MODEL_PATH)