# -*- coding: utf-8 -*-
"""TCN_pytorch_workflow_Focalloss02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17auX5NwS0FjdptJNhXJvWLqEBbcGIHia
"""

# ##############################################################################
# @title ì…€ 1 (Focal Lossìš©): ê¸°ë³¸ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ##############################################################################
from google.colab import files
import os
import glob
import pandas as pd
import numpy as np
from collections import Counter

import torch
import torch.nn as nn
import torch.nn.functional as F # Focal Loss êµ¬í˜„ì— í•„ìš”
from torch.utils.data import Dataset, DataLoader

from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score

# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# GPU ì‚¬ìš© ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
print("-" * 50)

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
class Config:
    # --- ë°ì´í„° ê´€ë ¨ ---
    SEQUENCE_LENGTH = 20

    # --- í›ˆë ¨ ê´€ë ¨ ---
    OPTIMIZER = 'AdamW'
    LEARNING_RATE = 1e-4
    BATCH_SIZE = 64
    EPOCHS = 50 # ë‹¨ì¼ í›ˆë ¨ì´ë¯€ë¡œ ì—í¬í¬ ìˆ˜ë¥¼ ì¶©ë¶„íˆ ì„¤ì •

    # --- Focal Loss íŒŒë¼ë¯¸í„° (ë³´ê³ ì„œ í‘œ 4ì™€ ë³„ê°œ) ---
    # alpha: í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜. ì†Œìˆ˜ í´ë˜ìŠ¤(1)ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ë¶ˆê· í˜•ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.
    # ì¼ë°˜ì ìœ¼ë¡œ 0.25 ë˜ëŠ” (1 - ì†Œìˆ˜ í´ë˜ìŠ¤ ë¹„ìœ¨) ë“±ì„ ì‚¬ìš©í•˜ë©°, íŠœë‹ ëŒ€ìƒì…ë‹ˆë‹¤.
    FOCAL_LOSS_ALPHA = 0.25
    # gamma: Focusing íŒŒë¼ë¯¸í„°. ëª¨ë¸ì´ ì´ë¯¸ ì˜ ë§íˆëŠ” 'ì‰¬ìš´' ìƒ˜í”Œì˜ ì†ì‹¤ì€ ì¤„ì´ê³ ,
    # ë§íˆê¸° 'ì–´ë ¤ìš´' ìƒ˜í”Œì— ë” ì§‘ì¤‘í•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤. 2~5 ì‚¬ì´ì˜ ê°’ì„ ì£¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    FOCAL_LOSS_GAMMA = 2

    # --- ëª¨ë¸ ì•„í‚¤í…ì²˜ ê´€ë ¨ (TCN) ---
    TCN_INPUT_CHANNELS = -1
    TCN_NUM_CHANNELS = [256] * 2
    TCN_KERNEL_SIZE = 3
    DROPOUT = 0.2

# ì„¤ì •ê°’ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
config = Config()

# ##############################################################################
# @title ì…€ 2 (Focal Lossìš©): Focal Loss í•¨ìˆ˜ ì •ì˜
# ##############################################################################

class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        """
        Args:
            inputs: ëª¨ë¸ì˜ ì˜ˆì¸¡ ë¡œì§“ (Batch, Num_Classes)
            targets: ì‹¤ì œ ë ˆì´ë¸” (Batch,)
        """
        # í‘œì¤€ Cross Entropy Loss ê³„ì‚°
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')

        # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ì˜ í™•ë¥ (pt) ê³„ì‚° (pt = e^(-ce_loss))
        pt = torch.exp(-ce_loss)

        # Focal Loss ê³„ì‚°: (1-pt)^gamma * ce_loss
        focal_loss = ((1 - pt) ** self.gamma) * ce_loss

        # Alpha ê°€ì¤‘ì¹˜ ì ìš© (ì„ íƒ ì‚¬í•­)
        if self.alpha is not None:
            # targets í…ì„œì™€ ë™ì¼í•œ ë””ë°”ì´ìŠ¤ ë° íƒ€ì…ìœ¼ë¡œ alpha_t í…ì„œ ìƒì„±
            alpha_t = torch.full_like(targets, 1 - self.alpha, device=targets.device, dtype=torch.float32)
            # targets ê°’ì´ 1ì¸ ìœ„ì¹˜ì— alpha ê°’ì„ ì ìš©
            alpha_t[targets == 1] = self.alpha
            focal_loss = alpha_t * focal_loss

        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

print("FocalLoss í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ##############################################################################
# @title ì…€ 2 (í†µí•© ëª¨ë¸ìš©): ë°ì´í„° ë¡œë”© (ì–‘ì† í†µí•©) - ìˆ˜ì •ëœ ë²„ì „
# ##############################################################################
import os
import glob
import pandas as pd
import numpy as np
from collections import Counter
from google.colab import drive

# 1. Google Drive ë§ˆìš´íŠ¸
# ì´ë¯¸ ë§ˆìš´íŠ¸ëœ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ try-except êµ¬ë¬¸ ì‚¬ìš©
try:
    drive.mount('/content/drive')
except Exception as e:
    print(f"Drive ë§ˆìš´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ë˜ëŠ” ì´ë¯¸ ë§ˆìš´íŠ¸ë¨: {e}")

# 2. ë°ì´í„° ê²½ë¡œ ì„¤ì •
# ë°ì´í„°ê°€ ì €ì¥ëœ ìµœìƒìœ„ í´ë”ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
# ì˜ˆ: /content/drive/MyDrive/gesture_data_v3
BASE_DATA_DIR = '/content/drive/MyDrive/gesture_data_v3'

# 3. ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ CSV íŒŒì¼ ê²€ìƒ‰
# BASE_DATA_DIR ì•„ë˜ì˜ ëª¨ë“  í´ë”(**/)ì— ìˆëŠ” ëª¨ë“  csvíŒŒì¼(*.csv)ì„ ì°¾ìŠµë‹ˆë‹¤.
FILE_PATTERN = os.path.join(BASE_DATA_DIR, '**', '*.csv')

print(f"'{FILE_PATTERN}' íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
# recursive=True ì˜µì…˜ìœ¼ë¡œ ëª¨ë“  í•˜ìœ„ í´ë”ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.
all_files = glob.glob(FILE_PATTERN, recursive=True)

# 4. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ë°ì´í„° ë¡œë”©
if not all_files:
    print(f"\n[ì˜¤ë¥˜] '{FILE_PATTERN}' íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ì•„ë˜ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
    print(f"1. Google Driveê°€ '/content/drive'ì— ì˜¬ë°”ë¥´ê²Œ ë§ˆìš´íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸")
    print(f"2. ê¸°ë³¸ ê²½ë¡œ '{BASE_DATA_DIR}'ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
    print(f"3. í•´ë‹¹ ê²½ë¡œ ë° í•˜ìœ„ í´ë”ì— '.csv' í™•ì¥ìë¥¼ ê°€ì§„ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸")
else:
    print(f"\nì´ {len(all_files)}ê°œì˜ CSV íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        # 5. ëª¨ë“  CSV íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        df_list = [pd.read_csv(f) for f in all_files]
        combined_df = pd.concat(df_list, ignore_index=True)
        print(f"\nì´ {len(all_files)}ê°œì˜ íŒŒì¼ì—ì„œ {len(combined_df)}ê°œì˜ í”„ë ˆì„ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        print(f"ì´ˆê¸° ë ˆì´ë¸” ë¶„í¬:\n{combined_df['label'].value_counts()}\n")

        # 6. í”¼ì²˜(X)ì™€ ë ˆì´ë¸”(y) ë¶„ë¦¬ ë° íƒ€ì… ë³€í™˜
        X_raw = combined_df.drop('label', axis=1).values
        y_raw = combined_df['label'].values.astype(int)

        # 7. ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± í•¨ìˆ˜ (config.SEQUENCE_LENGTHê°€ ë¯¸ë¦¬ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨)
        # ì˜ˆì‹œ: config ê°ì²´ê°€ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ì„ì‹œ ì •ì˜
        # class Config: SEQUENCE_LENGTH = 10
        # config = Config()
        def create_sequences(X, y, sequence_length):
            X_seq, y_seq = [], []
            for i in range(len(X) - sequence_length + 1):
                X_seq.append(X[i:i + sequence_length])
                y_seq.append(y[i + sequence_length - 1])
            return np.array(X_seq), np.array(y_seq)

        # 8. ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± ì‹¤í–‰
        # ì•„ë˜ ì½”ë“œ ì‹¤í–‰ ì „ 'config.SEQUENCE_LENGTH' ê°’ì´ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        X_sequences, y_sequences = create_sequences(X_raw, y_raw, config.SEQUENCE_LENGTH)

        # 9. ëª¨ë¸ì˜ ì…ë ¥ ì±„ë„ ìˆ˜ë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •
        # ì•„ë˜ ì½”ë“œ ì‹¤í–‰ ì „ 'config' ê°ì²´ê°€ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        config.TCN_INPUT_CHANNELS = X_sequences.shape[2]

        print("ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
        print(f"X í˜•íƒœ: {X_sequences.shape}")
        print(f"y í˜•íƒœ: {y_sequences.shape}")
        print(f"ë³€í™˜ í›„ ë ˆì´ë¸” ë¶„í¬: {Counter(y_sequences)}")
        print(f"ëª¨ë¸ ì…ë ¥ ì±„ë„ ìˆ˜ (config.TCN_INPUT_CHANNELS): {config.TCN_INPUT_CHANNELS}")

    except Exception as e:
        print(f"\n[ì˜¤ë¥˜] ë°ì´í„° ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("CSV íŒŒì¼ í˜•ì‹ì´ ëª¨ë‘ ë™ì¼í•œì§€, ëª¨ë“  íŒŒì¼ì— 'label' ì—´ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

# ##############################################################################
# @title ì…€ 3 (í†µí•© ëª¨ë¸ìš©): ë°ì´í„° ì¦ê°• (ì¢Œìš° ë°˜ì „ ì¶”ê°€)
# ##############################################################################

def augment_horizontal_flip(sequence: np.ndarray) -> np.ndarray:
    """
    ëœë“œë§ˆí¬ ì‹œí€€ìŠ¤ë¥¼ Y-Z í‰ë©´(x=0)ì„ ê¸°ì¤€ìœ¼ë¡œ ì¢Œìš° ë°˜ì „ì‹œí‚µë‹ˆë‹¤.
    x ì¢Œí‘œì— -1ì„ ê³±í•˜ì—¬ ê°„ë‹¨íˆ êµ¬í˜„í•©ë‹ˆë‹¤.
    """
    flipped_sequence = sequence.copy()
    # x ì¢Œí‘œëŠ” 3ê°œë§ˆë‹¤ í•˜ë‚˜ì”© ìœ„ì¹˜ (x0, y0, z0, x1, y1, z1, ...)
    # [:, ::3]ëŠ” ëª¨ë“  í”„ë ˆì„ì— ëŒ€í•´, 0ë²ˆ featureë¶€í„° 3ì¹¸ì”© ê±´ë„ˆë›°ë©° ì„ íƒ
    flipped_sequence[:, ::3] = -1 * flipped_sequence[:, ::3]
    return flipped_sequence

def augment_rotate(sequence: np.ndarray, max_angle_deg: float = 10.0) -> np.ndarray:
    # (ì´ì „ê³¼ ë™ì¼í•œ ì½”ë“œ)
    original_shape = sequence.shape
    if original_shape[1] % 3 != 0: return sequence
    num_points = original_shape[1] // 3
    sequence_reshaped = sequence.reshape(original_shape[0], num_points, 3)
    angle_rad = np.random.uniform(-max_angle_deg, max_angle_deg) * (np.pi / 180.0)
    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)
    rotation_matrix = np.array([[cos_a, -sin_a, 0], [sin_a, cos_a, 0], [0, 0, 1]])
    rotated_sequence_reshaped = np.dot(sequence_reshaped, rotation_matrix)
    return rotated_sequence_reshaped.reshape(original_shape)

def augment_scale(sequence: np.ndarray, min_scale: float = 0.9, max_scale: float = 1.1) -> np.ndarray:
    # (ì´ì „ê³¼ ë™ì¼í•œ ì½”ë“œ)
    scale = np.random.uniform(min_scale, max_scale)
    return sequence * scale

def augment_jitter(sequence: np.ndarray, std: float = 0.01) -> np.ndarray:
    # (ì´ì „ê³¼ ë™ì¼í•œ ì½”ë“œ)
    noise = np.random.normal(loc=0.0, scale=std, size=sequence.shape)
    return sequence + noise

# --- ì˜¨ë¼ì¸ ì¦ê°•ì„ ì ìš©í•˜ëŠ” Custom Dataset í´ë˜ìŠ¤ ---
class GestureDataset(Dataset):
    def __init__(self, X, y, sequence_length, apply_augmentations=False):
        self.X = X
        self.y = y
        self.sequence_length = sequence_length
        self.apply_augmentations = apply_augmentations

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        x_item = self.X[idx].copy()
        y_item = self.y[idx]

        if self.apply_augmentations:
            # [í•µì‹¬ ë³€ê²½ì ] 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „ ì¦ê°•ì„ ë¨¼ì € ì ìš©
            if np.random.random() < 0.5:
                x_item = augment_horizontal_flip(x_item)

            # ê¸°ì¡´ì˜ ê³µê°„ì  ì¦ê°•ë“¤ì„ì´ì–´ì„œ ì ìš©
            x_item = augment_rotate(x_item)
            x_item = augment_scale(x_item)
            x_item = augment_jitter(x_item)

        x_tensor = torch.FloatTensor(x_item)
        y_tensor = torch.LongTensor([y_item]).squeeze()

        return x_tensor, y_tensor

print("ë°ì´í„° ì¦ê°• í•¨ìˆ˜ ë° Custom Dataset í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤. (ì¢Œìš° ë°˜ì „ ì¶”ê°€ ì™„ë£Œ)")

# ##############################################################################
# @title ì…€ 4 (ìˆ˜ì •ë¨): TCN ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜
# ##############################################################################

class TemporalBlock(nn.Module):
    """
    TCNì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œì¸ Temporal Blockì…ë‹ˆë‹¤.
    [ìˆ˜ì • ì‚¬í•­] ì»¨ë³¼ë£¨ì…˜ ì´í›„ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì›ë³¸ê³¼ ë™ì¼í•˜ê²Œ ë§ì¶”ê¸° ìœ„í•´ ìŠ¬ë¼ì´ì‹± ë¡œì§ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):
        super(TemporalBlock, self).__init__()
        # nn.utils.weight_normì„ conv ë ˆì´ì–´ì— ì§ì ‘ ì ìš©í•©ë‹ˆë‹¤.
        self.conv1 = nn.utils.weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,
                                           stride=stride, padding=padding, dilation=dilation))
        self.padding1 = padding # ìŠ¬ë¼ì´ì‹±ì— ì‚¬ìš©í•  íŒ¨ë”© ê°’ì„ ì €ì¥
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(dropout)

        self.conv2 = nn.utils.weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,
                                           stride=stride, padding=padding, dilation=dilation))
        self.padding2 = padding # ìŠ¬ë¼ì´ì‹±ì— ì‚¬ìš©í•  íŒ¨ë”© ê°’ì„ ì €ì¥
        self.relu2 = nn.ReLU()
        self.dropout2 = nn.Dropout(dropout)

        # ë‹¤ìš´ìƒ˜í”Œë§ ë ˆì´ì–´ëŠ” ì…ë ¥ê³¼ ì¶œë ¥ì˜ ì±„ë„ ìˆ˜ê°€ ë‹¤ë¥¼ ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None
        self.relu = nn.ReLU()

    def forward(self, x):
        # x: (Batch, Channels, Seq_Len)

        # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡
        out = self.conv1(x)
        # ëŠ˜ì–´ë‚œ íŒ¨ë”©ë§Œí¼ ëë¶€ë¶„ì„ ì˜ë¼ë‚´ì–´ ê¸¸ì´ë¥¼ ë§ì¶¤ (Causal Convolution)
        out = out[:, :, :-self.padding1]
        out = self.relu1(out)
        out = self.dropout1(out)

        # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡
        out = self.conv2(out)
        out = out[:, :, :-self.padding2]
        out = self.relu2(out)
        out = self.dropout2(out)

        # ì”ì°¨ ì—°ê²° (Residual Connection)
        res = x if self.downsample is None else self.downsample(x)

        # ì´ì œ outê³¼ resì˜ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ë™ì¼í•˜ë¯€ë¡œ ë§ì…ˆì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        return self.relu(out + res)


class TCN(nn.Module):
    """
    Temporal Convolutional Network ëª¨ë¸ì…ë‹ˆë‹¤.
    ë³´ê³ ì„œ í‘œ 4ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì„±ë©ë‹ˆë‹¤.
    """
    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):
        super(TCN, self).__init__()
        layers = []
        num_levels = len(num_channels)
        for i in range(num_levels):
            dilation_size = 2 ** i
            in_channels = input_size if i == 0 else num_channels[i-1]
            out_channels = num_channels[i]
            # ì¸ê³¼ì  ì»¨ë³¼ë£¨ì…˜ì„ ìœ„í•œ íŒ¨ë”© ê³„ì‚°
            padding = (kernel_size - 1) * dilation_size
            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,
                                     padding=padding, dropout=dropout)]

        self.tcn = nn.Sequential(*layers)
        self.linear = nn.Linear(num_channels[-1], output_size)

    def forward(self, x):
        # ì…ë ¥: (Batch, Seq_Len, Features)
        # TCNì€ (Batch, Features, Seq_Len) í˜•íƒœë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ì°¨ì› ë³€ê²½
        x = x.permute(0, 2, 1)

        out = self.tcn(x)

        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì¶œë ¥ë§Œ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜
        out = self.linear(out[:, :, -1])
        return out

print("TCN ëª¨ë¸ ì•„í‚¤í…ì²˜ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤. (ìˆ˜ì • ì™„ë£Œ)")

# ##############################################################################
# @title ì…€ 5: í›ˆë ¨ ë° í‰ê°€ í•¨ìˆ˜ ì •ì˜
# ##############################################################################
from tqdm.auto import tqdm # ì§„í–‰ ìƒí™©ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

def train_one_epoch(model, data_loader, criterion, optimizer, device):
    """í•œ ì—í¬í¬ ë™ì•ˆ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” í•¨ìˆ˜"""
    model.train()
    total_loss = 0

    for inputs, labels in tqdm(data_loader, desc="Training", leave=False):
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(data_loader)

def evaluate(model, data_loader, criterion, device):
    """ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜"""
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in tqdm(data_loader, desc="Evaluating", leave=False):
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            total_loss += loss.item()

            preds = torch.argmax(outputs, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    avg_loss = total_loss / len(data_loader)

    # ë³´ê³ ì„œì—ì„œ ê¶Œì¥í•˜ëŠ” F1-Scoreë¥¼ í¬í•¨í•œ í‰ê°€ì§€í‘œ ê³„ì‚° [cite: 91]
    metrics = {
        'loss': avg_loss,
        'f1_score': f1_score(all_labels, all_preds, average='binary'),
        'accuracy': accuracy_score(all_labels, all_preds),
        'precision': precision_score(all_labels, all_preds, average='binary'),
        'recall': recall_score(all_labels, all_preds, average='binary')
    }

    return metrics

print("í›ˆë ¨ ë° í‰ê°€ í•¨ìˆ˜ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ##############################################################################
# @title ìµœì¢… ì‹¤í–‰ ì…€ (Focal Lossìš©): ğŸš€ ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰
# ##############################################################################
print("--- Focal Loss ê¸°ë°˜ TCN ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ---")

# ì´ ì…€ì„ ì‹¤í–‰í•˜ê¸° ì „ì—, ì´ì „ TCN ì›Œí¬í”Œë¡œìš°ì˜
# [ì…€ 2: ë°ì´í„° ë¡œë“œ], [ì…€ 3: ë°ì´í„° ì¦ê°•], [ì…€ 4: TCN ëª¨ë¸ ì •ì˜], [ì…€ 5: í›ˆë ¨/í‰ê°€ í•¨ìˆ˜]ê°€
# ë¨¼ì € ì‹¤í–‰ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

# 1. ì›ë³¸ ë¶ˆê· í˜• ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬
# T-SMOTEë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì›ë³¸ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ë°”ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
X_train, X_val, y_train, y_val = train_test_split(
    X_sequences, y_sequences,
    test_size=0.2,
    random_state=SEED,
    stratify=y_sequences # ë¶ˆê· í˜• ë°ì´í„°ì´ë¯€ë¡œ stratifyê°€ ì¤‘ìš”
)

# 2. í›ˆë ¨ìš©/ê²€ì¦ìš© Dataset ë° DataLoader ìƒì„± (ê³µê°„ ì¦ê°• ì ìš©)
train_dataset = GestureDataset(X_train, y_train, config.SEQUENCE_LENGTH, apply_augmentations=True)
val_dataset = GestureDataset(X_val, y_val, config.SEQUENCE_LENGTH, apply_augmentations=False)
train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False)
print(f"í›ˆë ¨ ë°ì´í„°: {len(train_dataset)}ê°œ, ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ")

# 3. TCN ëª¨ë¸, Focal Loss, ì˜µí‹°ë§ˆì´ì € ì •ì˜
model = TCN(
    input_size=config.TCN_INPUT_CHANNELS,
    output_size=2,
    num_channels=config.TCN_NUM_CHANNELS,
    kernel_size=config.TCN_KERNEL_SIZE,
    dropout=config.DROPOUT
).to(device)

# [í•µì‹¬ ë³€ê²½ ì‚¬í•­] CrossEntropyLoss ëŒ€ì‹  FocalLossë¥¼ ì†ì‹¤ í•¨ìˆ˜ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
criterion = FocalLoss(alpha=config.FOCAL_LOSS_ALPHA, gamma=config.FOCAL_LOSS_GAMMA)
optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)

print("\nëª¨ë¸ ì•„í‚¤í…ì²˜:")
print(model)
print(f"\nì†ì‹¤ í•¨ìˆ˜: FocalLoss (alpha={config.FOCAL_LOSS_ALPHA}, gamma={config.FOCAL_LOSS_GAMMA})")
print(f"ì´ {config.EPOCHS} ì—í¬í¬ ë™ì•ˆ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

# 4. í›ˆë ¨ ë£¨í”„ ì‹¤í–‰
best_f1_score = 0.0
FOCAL_LOSS_MODEL_PATH = 'focal_loss_model_tcn.pt'

for epoch in range(config.EPOCHS):
    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)
    val_metrics = evaluate(model, val_loader, criterion, device)

    print(
        f"Epoch {epoch+1}/{config.EPOCHS} | "
        f"Train Loss: {train_loss:.4f} | "
        f"Val Loss: {val_metrics['loss']:.4f} | "
        f"Val F1: {val_metrics['f1_score']:.4f} | "
        f"Val Acc: {val_metrics['accuracy']:.4f}"
    )

    # ê²€ì¦ F1-scoreê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì„ ìµœì¢… ëª¨ë¸ë¡œ ì €ì¥
    if val_metrics['f1_score'] > best_f1_score:
        best_f1_score = val_metrics['f1_score']
        torch.save(model.state_dict(), FOCAL_LOSS_MODEL_PATH)
        print(f"  -> ğŸ‰ New best model saved with F1-Score: {best_f1_score:.4f}")

print("-" * 50)
print(f"âœ… í›ˆë ¨ ì™„ë£Œ: Focal Loss ëª¨ë¸ì´ '{FOCAL_LOSS_MODEL_PATH}'ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print(f"ìµœê³  ê²€ì¦ F1-Score: {best_f1_score:.4f}")
files.download(FOCAL_LOSS_MODEL_PATH)